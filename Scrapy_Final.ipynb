{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPaatUSixvrobqXqOjI2yxg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/W1cked1nf1n1ty/Web_Scrapper/blob/main/Scrapy_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing Libraries\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "\n",
        "# set URL\n",
        "url =\"https://www.1mg.com/drugs-all-medicines\"\n",
        "\n",
        "\n",
        "# Setting header for requests as firefox browser\n",
        "headers = {\n",
        "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def fetchData(url):\n",
        "      data = {}\n",
        "      response = requests.get(url, headers=headers)\n",
        "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "      Medics = soup.find_all(\n",
        "          class_=\"style__font-bold___1k9Dl style__font-14px___YZZrf style__flex-row___2AKyf style__space-between___2mbvn style__padding-bottom-5px___2NrDR\"\n",
        "      )\n",
        "      for med in Medics:\n",
        "          med = med.text\n",
        "          tmp = med.split(\"MRP\")\n",
        "          data[tmp[0]] = tmp[-1]\n",
        "      return data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "i = 97   # a\n",
        "max_page = []\n",
        "while i <= 122:  # a-z\n",
        "    url = \"https://www.1mg.com/drugs-all-medicines?label=\"+chr(i)\n",
        "    response = requests.get(url, headers=headers)\n",
        "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "    a = soup.find_all(class_=\"button-text link-page\")\n",
        "    no = int(a[-1].text)\n",
        "    max_page.append(no)\n",
        "    i += 1\n",
        "\n",
        "\n",
        "    # tt\n",
        "\n",
        "    # Saving data in XLSX file\n",
        "def save_to_csv(data):\n",
        "      name = []\n",
        "      price = []\n",
        "      for key in data:\n",
        "          name.append(key)\n",
        "          price.append(data[key])\n",
        "      df = {\"Medicine Name\": name, \"Price\": price}\n",
        "      df = pd.DataFrame.from_dict(df)\n",
        "      df.to_excel(\"medicine.xlsx\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # funtion to get all the data for everey page\n",
        "def scrapy():\n",
        "      data = {}\n",
        "      j = 96\n",
        "      for page in max_page:\n",
        "          j += 1\n",
        "          i = 1\n",
        "          print(\"Working on \", chr(j))\n",
        "\n",
        "          while i <= (page -(page-10)):\n",
        "              url = (\n",
        "                  \"https://www.1mg.com/drugs-all-medicines?page=\"\n",
        "                  + str(i)\n",
        "                  + \"&label=\"\n",
        "                  + chr(j)\n",
        "              )\n",
        "              tmp = dict(fetchData(url))\n",
        "              data.update(tmp)\n",
        "              i += 1\n",
        "      print(\"Got all the data ..........................\")\n",
        "      print(\"Saving data in XLSX file ....................\")\n",
        "      save_to_csv(data)\n",
        "      print(\"Data saved in XLSX file .....................\")\n"
      ],
      "metadata": {
        "id": "kJyUUoLt1VKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scrapy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdfDBXk899Ik",
        "outputId": "5f48c239-4c9f-4446-cfdc-6c1776074fde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Working on  a\n",
            "Working on  b\n",
            "Working on  c\n",
            "Working on  d\n",
            "Working on  e\n",
            "Working on  f\n",
            "Working on  g\n",
            "Working on  h\n",
            "Working on  i\n",
            "Working on  j\n",
            "Working on  k\n",
            "Working on  l\n",
            "Working on  m\n",
            "Working on  n\n",
            "Working on  o\n",
            "Working on  p\n",
            "Working on  q\n",
            "Working on  r\n",
            "Working on  s\n",
            "Working on  t\n",
            "Working on  u\n",
            "Working on  v\n",
            "Working on  w\n",
            "Working on  x\n",
            "Working on  y\n",
            "Working on  z\n",
            "Got all the data ..........................\n",
            "Saving data in XLSX file ....................\n",
            "Data saved in XLSX file .....................\n"
          ]
        }
      ]
    }
  ]
}