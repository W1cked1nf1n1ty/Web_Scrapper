{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'bs4'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\7ram1\\Documents\\GitHub\\Web_Scrapper\\Web_scrapper.ipynb Cell 1\u001b[0m in \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/7ram1/Documents/GitHub/Web_Scrapper/Web_scrapper.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Importing Libraries\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/7ram1/Documents/GitHub/Web_Scrapper/Web_scrapper.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mrequests\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/7ram1/Documents/GitHub/Web_Scrapper/Web_scrapper.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mbs4\u001b[39;00m \u001b[39mimport\u001b[39;00m BeautifulSoup\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/7ram1/Documents/GitHub/Web_Scrapper/Web_scrapper.ipynb#W0sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mcollections\u001b[39;00m \u001b[39mimport\u001b[39;00m defaultdict\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/7ram1/Documents/GitHub/Web_Scrapper/Web_scrapper.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'bs4'"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "\n",
    "# set URL\n",
    "url =\"https://www.1mg.com/drugs-all-medicines\"\n",
    "\n",
    "\n",
    "# Setting header for requests as firefox browser\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fetchData(url):\n",
    "      data = {}\n",
    "      response = requests.get(url, headers=headers)\n",
    "      soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "      Medics = soup.find_all(\n",
    "          class_=\"style__font-bold___1k9Dl style__font-14px___YZZrf style__flex-row___2AKyf style__space-between___2mbvn style__padding-bottom-5px___2NrDR\"\n",
    "      )\n",
    "      for med in Medics:\n",
    "          med = med.text\n",
    "          tmp = med.split(\"MRP\")\n",
    "          data[tmp[0]] = tmp[-1]\n",
    "      return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "i = 97   # a\n",
    "max_page = []\n",
    "while i <= 122:  # a-z\n",
    "    url = \"https://www.1mg.com/drugs-all-medicines?label=\"+chr(i)\n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    a = soup.find_all(class_=\"button-text link-page\")\n",
    "    no = int(a[-1].text)\n",
    "    max_page.append(no)\n",
    "    i += 1\n",
    "\n",
    "\n",
    "    # tt\n",
    "\n",
    "    # Saving data in XLSX file\n",
    "def save_to_csv(data):\n",
    "      name = []\n",
    "      price = []\n",
    "      for key in data:\n",
    "          name.append(key)\n",
    "          price.append(data[key])\n",
    "      df = {\"Medicine Name\": name, \"Price\": price}\n",
    "      df = pd.DataFrame.from_dict(df)\n",
    "      df.to_excel(\"medicine.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # funtion to get all the data for everey page\n",
    "def scrapy():\n",
    "      data = {}\n",
    "      j = 96\n",
    "      for page in max_page:\n",
    "          j += 1\n",
    "          i = 1\n",
    "          print(\"Working on \", chr(j))\n",
    "\n",
    "          while i <= (page -(page-10)):\n",
    "              url = (\n",
    "                  \"https://www.1mg.com/drugs-all-medicines?page=\"\n",
    "                  + str(i)\n",
    "                  + \"&label=\"\n",
    "                  + chr(j)\n",
    "              )\n",
    "              tmp = dict(fetchData(url))\n",
    "              data.update(tmp)\n",
    "              i += 1\n",
    "      print(\"Got all the data ..........................\")\n",
    "      print(\"Saving data in XLSX file ....................\")\n",
    "      save_to_csv(data)\n",
    "      print(\"Data saved in XLSX file .....................\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
